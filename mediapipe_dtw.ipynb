{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resources Used\n",
    "- wget.download('https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/_downloads/da4babe668a8afb093cc7776d7e630f3/generate_tfrecord.py')\n",
    "- Setup https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/install.html\n",
    "\n",
    "https://google.github.io/mediapipe/solutions/pose_classification.html#colabs\n",
    "https://fr.acervolima.com/detection-de-reperes-de-visage-et-de-main-a-l-aide-de-python-mediapipe-opencv/\n",
    "https://medium.com/analytics-vidhya/human-pose-comparison-and-action-scoring-using-deep-learning-opencv-python-c2bdf0ddecba\n",
    "\n",
    "https://github.com/gabguerin/hand-gesture-recognition-mediapipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Setup Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "L=[1,2,3]\n",
    "print(np.array(L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [1 2 3]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "array = np.empty((0,3), int)\n",
    "\n",
    "array = np.append(array, np.array([L]), axis=0)\n",
    "array = np.append(array, np.array([L]), axis=0)\n",
    "\n",
    "print(array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import copy\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "class myClass:\n",
    "    def __init__(self, val):\n",
    "        self.val=val\n",
    "    def getVal(self):\n",
    "        return self.val  \n",
    "\n",
    "def read_video(path):\n",
    "    mp_hands = mp.solutions.hands\n",
    "    cap = cv2.VideoCapture(path)\n",
    "\n",
    "    #construct head of the dataframe\n",
    "    title=['frame']\n",
    "    for i in range(21):\n",
    "        title.append(str(i)+'_x')\n",
    "        title.append(str(i)+'_y')\n",
    "    df = pd.DataFrame(columns=title)\n",
    "\n",
    "    idx=0\n",
    "\n",
    "    with mp_hands.Hands(\n",
    "        model_complexity=0,\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5) as hands:\n",
    "        while cap.isOpened():\n",
    "            success, image = cap.read()\n",
    "            if not success:\n",
    "                print(\"Ignoring empty camera frame.\")\n",
    "                break\n",
    "\n",
    "            # To improve performance, optionally mark the image as not writeable to pass by reference.\n",
    "            image.flags.writeable = False\n",
    "            #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            results = hands.process(image)\n",
    "\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            if results.multi_hand_landmarks:\n",
    "                image_height, image_width, _ = image.shape\n",
    "\n",
    "            if results.multi_hand_landmarks:\n",
    "                L1=[]\n",
    "                L1.append(idx)\n",
    "                for i in range(21):\n",
    "                    try :\n",
    "                    #results.multi_handedness[0].classification[0].label\n",
    "                        L1.append(results.multi_hand_landmarks[0].landmark[i].x * image_width)\n",
    "                        L1.append(results.multi_hand_landmarks[0].landmark[i].y * image_height)\n",
    "                    except:\n",
    "                        L1.append(np.nan)\n",
    "                        L1.append(np.nan)\n",
    "                L1=normlization(L1)\n",
    "                df_temp = pd.Series(L1, index = df.columns)\n",
    "                df.loc[len(df)] = df_temp\n",
    "                idx+=1\n",
    "            \n",
    "            pressedKey = cv2.waitKey(1) & 0xFF\n",
    "            if pressedKey == ord(\"q\"):  # Record pressing r\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def normlization(L1):\n",
    "    L=copy.copy(L1)\n",
    "    #L=L[1:]\n",
    "    x_base,y_base=0,0\n",
    "    for i in range(1,len(L),2):\n",
    "        if(i==0):\n",
    "            x_base,y_base=L[0],L[1]\n",
    "            L[0],L[1]=0,0\n",
    "        else:\n",
    "            L[i]=L[i]-x_base\n",
    "            L[i+1]=L[i+1]-y_base\n",
    "    return L\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Main droite\n",
    "# results.multi_hand_landmarks[0]\n",
    "\n",
    "#hand_landmarks.landmark[1].x \n",
    "#results.multi_hand_landmarks[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6501518487930298"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results.multi_hand_landmarks[0]\n",
    "\n",
    "# hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Webcam with buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n",
      "len L1 :  43\n"
     ]
    }
   ],
   "source": [
    "# import cv2\n",
    "# import time\n",
    "# import mediapipe as mp\n",
    "# import collections\n",
    "# d = collections.deque(maxlen=30)\n",
    "\n",
    "# mp_drawing = mp.solutions.drawing_utils\n",
    "# mp_drawing_styles = mp.solutions.drawing_styles\n",
    "# mp_hands = mp.solutions.hands\n",
    "\n",
    "# # For webcam input:\n",
    "# cap = cv2.VideoCapture(0)\n",
    "# previousTime = 0\n",
    "# currentTime = 0\n",
    "\n",
    "# title=['frame']\n",
    "# for i in range(21):\n",
    "#     title.append(str(i)+'_x')\n",
    "#     title.append(str(i)+'_y')\n",
    "# df = pd.DataFrame(columns=title)\n",
    "# idx=0\n",
    "\n",
    "\n",
    "# with mp_hands.Hands(\n",
    "#     model_complexity=0,\n",
    "#     min_detection_confidence=0.5,\n",
    "#     min_tracking_confidence=0.5) as hands:\n",
    "#   while True:#cap.isOpened():\n",
    "#         # Find OpenCV version\n",
    "#     (major_ver, minor_ver, subminor_ver) = (cv2.__version__).split('.')\n",
    "\n",
    "#     success, image = cap.read()\n",
    "#     if not success:\n",
    "#       print(\"Ignoring empty camera frame.\")\n",
    "#       # If loading a video, use 'break' instead of 'continue'.\n",
    "#       continue\n",
    "\n",
    "#     # To improve performance, optionally mark the image as not writeable to\n",
    "#     # pass by reference.\n",
    "#     image.flags.writeable = False\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#     results = hands.process(image)\n",
    "\n",
    "#     image.flags.writeable = True\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "#     if results.multi_hand_landmarks:\n",
    "#       for hand_landmarks in results.multi_hand_landmarks:\n",
    "#         mp_drawing.draw_landmarks(\n",
    "#             image,\n",
    "#             hand_landmarks,\n",
    "#             mp_hands.HAND_CONNECTIONS,\n",
    "#             mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "#             mp_drawing_styles.get_default_hand_connections_style())\n",
    "\n",
    "#     if results.multi_hand_landmarks:\n",
    "#       image_height, image_width, _ = image.shape\n",
    "\n",
    "#     if results.multi_hand_landmarks:\n",
    "#       L1=[]\n",
    "#       L1.append(idx)\n",
    "#       for i in range(21):\n",
    "#           try :\n",
    "#           #results.multi_handedness[0].classification[0].label\n",
    "#               L1.append(results.multi_hand_landmarks[0].landmark[i].x * image_width)\n",
    "#               L1.append(results.multi_hand_landmarks[0].landmark[i].y * image_height)\n",
    "#           except:\n",
    "#               L1.append(np.nan)\n",
    "#               L1.append(np.nan)\n",
    "\n",
    "#     d.append(normlization(L1))\n",
    "#     idx+=1\n",
    "    \n",
    "#     image=cv2.flip(image, 1)\n",
    "#     # Calculating the FPS\n",
    "#     currentTime = time.time()\n",
    "#     fps = 1 / (currentTime-previousTime)\n",
    "#     previousTime = currentTime\n",
    "#     # Displaying FPS on the image\n",
    "#     cv2.putText(image, str(int(fps))+\" FPS\", (10, 70), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "#     # Flip the image horizontally for a selfie-view display.\n",
    "#     cv2.imshow('MediaPipe Hands', image)\n",
    "\n",
    "#     pressedKey = cv2.waitKey(1) & 0xFF\n",
    "#     if pressedKey == ord(\"q\"):  # Record pressing r\n",
    "#       cap.release()\n",
    "#       break\n",
    "\n",
    "\n",
    "# #print(d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hmm_models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\franc\\Documents\\GitHub\\AIMOVE_AGV_AI\\mediapipe_dtw.ipynb Cell 10'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/franc/Documents/GitHub/AIMOVE_AGV_AI/mediapipe_dtw.ipynb#ch0000009?line=82'>83</a>\u001b[0m \u001b[39mif\u001b[39;00m (idx\u001b[39m>\u001b[39m\u001b[39m30\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/franc/Documents/GitHub/AIMOVE_AGV_AI/mediapipe_dtw.ipynb#ch0000009?line=83'>84</a>\u001b[0m   resultats\u001b[39m=\u001b[39m[]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/franc/Documents/GitHub/AIMOVE_AGV_AI/mediapipe_dtw.ipynb#ch0000009?line=84'>85</a>\u001b[0m   \u001b[39mfor\u001b[39;00m hmm_model_num \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(hmm_models)):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/franc/Documents/GitHub/AIMOVE_AGV_AI/mediapipe_dtw.ipynb#ch0000009?line=85'>86</a>\u001b[0m       res\u001b[39m=\u001b[39mhmm_models[hmm_model_num]\u001b[39m.\u001b[39mscore(np\u001b[39m.\u001b[39marray(buff_np))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/franc/Documents/GitHub/AIMOVE_AGV_AI/mediapipe_dtw.ipynb#ch0000009?line=86'>87</a>\u001b[0m       resultats\u001b[39m.\u001b[39mappend(res)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hmm_models' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import mediapipe as mp\n",
    "import collections\n",
    "d = collections.deque(maxlen=30)\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# For webcam input:\n",
    "cap = cv2.VideoCapture(0)\n",
    "previousTime = 0\n",
    "currentTime = 0\n",
    "\n",
    "seuil=-10000\n",
    "buff_np=np.zeros([30,42])\n",
    "\n",
    "title=['frame']\n",
    "for i in range(21):\n",
    "    title.append(str(i)+'_x')\n",
    "    title.append(str(i)+'_y')\n",
    "df = pd.DataFrame(columns=title)\n",
    "idx=0\n",
    "\n",
    "hands= mp_hands.Hands(\n",
    "    model_complexity=0,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5)\n",
    "\n",
    "# with mp_hands.Hands(\n",
    "#     model_complexity=0,\n",
    "#     min_detection_confidence=0.5,\n",
    "#     min_tracking_confidence=0.5) as hands:\n",
    "while True:#cap.isOpened():\n",
    "      # Find OpenCV version\n",
    "  (major_ver, minor_ver, subminor_ver) = (cv2.__version__).split('.')\n",
    "\n",
    "  success, image = cap.read()\n",
    "  if not success:\n",
    "    print(\"Ignoring empty camera frame.\")\n",
    "    # If loading a video, use 'break' instead of 'continue'.\n",
    "    continue\n",
    "\n",
    "  # To improve performance, optionally mark the image as not writeable to\n",
    "  # pass by reference.\n",
    "  image.flags.writeable = False\n",
    "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "  results = hands.process(image)\n",
    "\n",
    "  image.flags.writeable = True\n",
    "  image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "  \n",
    "  if results.multi_hand_landmarks:\n",
    "    for hand_landmarks in results.multi_hand_landmarks:\n",
    "      mp_drawing.draw_landmarks(\n",
    "          image,\n",
    "          hand_landmarks,\n",
    "          mp_hands.HAND_CONNECTIONS,\n",
    "          mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "          mp_drawing_styles.get_default_hand_connections_style())\n",
    "\n",
    "  if results.multi_hand_landmarks:\n",
    "    image_height, image_width, _ = image.shape\n",
    "  L1=[]\n",
    "  if results.multi_hand_landmarks:\n",
    "    L1=[]\n",
    "    L1.append(idx)\n",
    "    for i in range(21):\n",
    "        try :\n",
    "        #results.multi_handedness[0].classification[0].label\n",
    "            L1.append(results.multi_hand_landmarks[0].landmark[i].x * image_width)\n",
    "            L1.append(results.multi_hand_landmarks[0].landmark[i].y * image_height)\n",
    "        except:\n",
    "            L1.append(np.nan)\n",
    "            L1.append(np.nan)\n",
    "\n",
    "  d.append(normlization(L1))\n",
    "  buff_np = np.array(d)[:, 1:]\n",
    "  #buff_np = np.array(d)\n",
    "\n",
    "  idx+=1\n",
    "  if (idx>30):\n",
    "    resultats=[]\n",
    "    for hmm_model_num in range(len(hmm_models)):\n",
    "        res=hmm_models[hmm_model_num].score(np.array(buff_np))\n",
    "        resultats.append(res)\n",
    "    print(resultats)\n",
    "    ide=resultats.index(max(resultats))\n",
    "    print(\"Best model : \", classes[ide])\n",
    "    \n",
    "    # seuil=-20000\n",
    "    # if (max(resultats) > seuil):\n",
    "    #   ide=resultats.index(max(resultats))\n",
    "    #   print(\"Best model : \", classes[ide])\n",
    "    # else:\n",
    "    #   print(\"No matching signs \")\n",
    "\n",
    "  \n",
    "  image=cv2.flip(image, 1)\n",
    "  # Calculating the FPS\n",
    "  currentTime = time.time()\n",
    "  fps = 1 / (currentTime-previousTime)\n",
    "  previousTime = currentTime\n",
    "  # Displaying FPS on the image\n",
    "  cv2.putText(image, str(int(fps))+\" FPS\", (10, 70), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "  # Flip the image horizontally for a selfie-view display.\n",
    "  cv2.imshow('MediaPipe Hands', image)\n",
    "\n",
    "  pressedKey = cv2.waitKey(1) & 0xFF\n",
    "  if pressedKey == ord(\"q\"): \n",
    "    cap.release()\n",
    "    break\n",
    "\n",
    "#print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try :\n",
    "    ax = results.multi_handedness[0].classification[0].label\n",
    "    \n",
    "except:\n",
    "    print(\"z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands\n",
    "L=[0,0,0,0,0]\n",
    "\n",
    "previousTime = 0\n",
    "currentTime = 0\n",
    "\n",
    "# For webcam input:\n",
    "#cap = cv2.VideoCapture(0)\n",
    "\n",
    "# For video on the laptop:\n",
    "cap = cv2.VideoCapture(r'C:\\Users\\franc\\Desktop\\RT_Detection_AGV\\data\\pouce\\pouce_test.mp4')\n",
    "\n",
    "title=['frame']\n",
    "for i in range(21):\n",
    "  title.append(str(i)+'_x')\n",
    "  title.append(str(i)+'_y')\n",
    "df = pd.DataFrame(columns=title)#['frame','x_r_hand','y_r_hand','x_l_hand','y_l_hand'])\n",
    "\n",
    "idx,x=0,0\n",
    "data=np.array([])\n",
    "\n",
    "with mp_hands.Hands(\n",
    "    model_complexity=0,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as hands:\n",
    "  while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "      print(\"Ignoring empty camera frame.\")\n",
    "      break\n",
    "      # If loading a video, use 'break' instead of 'continue'.\n",
    "      continue\n",
    "\n",
    "    # To improve performance, optionally mark the image as not writeable to pass by reference.\n",
    "    image.flags.writeable = False\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(image)\n",
    "\n",
    "    # Draw the hand annotations on the image.\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "   \n",
    "    if results.multi_hand_landmarks:\n",
    "      image_height, image_width, _ = image.shape\n",
    "      for hand_landmarks in results.multi_hand_landmarks:\n",
    "   \n",
    "        mp_drawing.draw_landmarks(\n",
    "            image,\n",
    "            hand_landmarks,\n",
    "            mp_hands.HAND_CONNECTIONS,\n",
    "            mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "            mp_drawing_styles.get_default_hand_connections_style())\n",
    "    # Flip the image horizontally for a selfie-view display.\n",
    "    image=cv2.flip(image, 1)\n",
    "    # Calculating the FPS\n",
    "    currentTime = time.time()\n",
    "    fps = 1 / (currentTime-previousTime)\n",
    "    previousTime = currentTime\n",
    "    # Displaying FPS on the image\n",
    "    cv2.putText(image, str(int(fps))+\" FPS\", (10, 70), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "    # Flip the image horizontally for a selfie-view display.\n",
    "    cv2.imshow('MediaPipe Hands', image)\n",
    "    \n",
    "    pressedKey = cv2.waitKey(1) & 0xFF\n",
    "    if pressedKey == ord(\"q\"):  # Record pressing r\n",
    "      break\n",
    "\n",
    "  cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path of the classes : \n",
      "[['C:\\\\Users\\\\franc\\\\Desktop\\\\RT_Detection_AGV\\\\data\\\\train\\\\five'], ['C:\\\\Users\\\\franc\\\\Desktop\\\\RT_Detection_AGV\\\\data\\\\train\\\\pouce']]\n",
      "C:\\\\Users\\\\franc\\\\Desktop\\\\RT_Detection_AGV\\\\data\\\\train\\\\five\\test3.mp4\n",
      "C:\\\\Users\\\\franc\\\\Desktop\\\\RT_Detection_AGV\\\\data\\\\train\\\\pouce\\pouce_train.mp4\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "path = r'C:\\Users\\franc\\Desktop\\RT_Detection_AGV\\data\\train'\n",
    "train_dir=[]\n",
    "\n",
    "classes = next(os.walk( path) )\n",
    "classes=classes[1]\n",
    "\n",
    "for num_classes in range(len(classes)):\n",
    "    train_dir.append(glob.glob(path+\"\\\\\"+classes[num_classes]))\n",
    "print(\"path of the classes : \")\n",
    "print(train_dir)\n",
    "\n",
    "for gesture in range(len(train_dir)):\n",
    "    for filename in glob.iglob(str(train_dir[gesture])[2:-2]+'\\\\\\\\*', recursive=True):\n",
    "        print(filename)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test download all the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [01:53<01:53, 113.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring empty camera frame.\n",
      "(995, 42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [03:56<00:00, 118.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring empty camera frame.\n",
      "(945, 42)\n",
      "(2,)\n",
      "[[995], [945]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)\n",
    "train_arrays_lengths=[]\n",
    "gestures_list=[]\n",
    "list_gesture=[]\n",
    "\n",
    "for gesture in tqdm(range(len(train_dir))):\n",
    "    for filename in glob.iglob(str(train_dir[gesture])[2:-2]+'\\\\\\\\*', recursive=True):\n",
    "        V=read_video(filename).to_numpy()\n",
    "        continue\n",
    "    V=V[:, 1:]\n",
    "    print(V.shape)\n",
    "    #V = np.expand_dims(V, axis = 0)\n",
    "    list_gesture.append(V)\n",
    "    train_arrays_lengths.append([V.shape[0]])\n",
    "    \n",
    "train_arrays= np.array(list_gesture, dtype=object)\n",
    "\n",
    "print(train_arrays.shape)\n",
    "print(train_arrays_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "T=copy.copy(train_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1940, 42)\n"
     ]
    }
   ],
   "source": [
    "data = np.empty((0,42))\n",
    "for i in range(train_arrays.shape[0]): data=np.append(data,train_arrays[i], axis=0)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1940"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n",
      "(2,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 2 into shape (42)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\franc\\Documents\\GitHub\\AIMOVE_AGV_AI\\mediapipe_dtw.ipynb Cell 21'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/franc/Documents/GitHub/AIMOVE_AGV_AI/mediapipe_dtw.ipynb#ch0000068?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(train_arrays\u001b[39m.\u001b[39mshape)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/franc/Documents/GitHub/AIMOVE_AGV_AI/mediapipe_dtw.ipynb#ch0000068?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(T\u001b[39m.\u001b[39mshape)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/franc/Documents/GitHub/AIMOVE_AGV_AI/mediapipe_dtw.ipynb#ch0000068?line=4'>5</a>\u001b[0m T\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m42\u001b[39;49m)\u001b[39m.\u001b[39mshape\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 2 into shape (42)"
     ]
    }
   ],
   "source": [
    "T=train_arrays\n",
    "print(train_arrays.shape)\n",
    "print(T.shape)\n",
    "\n",
    "T.reshape(-1, 42).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To save as pinkle\n",
    "import pickle\n",
    "file_name = \"save_train_data.pkl\"\n",
    "train_arrays=np.array([])\n",
    "\n",
    "open_file = open(file_name, \"wb\")\n",
    "pickle.dump(train_arrays, open_file)\n",
    "open_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To read pinkle file\n",
    "import pickle\n",
    "file_name = \"save_train_data.pkl\"\n",
    "\n",
    "open_file = open(file_name, \"rb\")\n",
    "train_arrays = pickle.load(open_file)\n",
    "open_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_arrays.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_arrays_lengths' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\franc\\Documents\\GitHub\\AIMOVE_AGV_AI\\mediapipe_dtw.ipynb Cell 23'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/franc/Documents/GitHub/AIMOVE_AGV_AI/mediapipe_dtw.ipynb#ch0000022?line=8'>9</a>\u001b[0m     \u001b[39mprint\u001b[39m(tmp)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/franc/Documents/GitHub/AIMOVE_AGV_AI/mediapipe_dtw.ipynb#ch0000022?line=9'>10</a>\u001b[0m     train_arrays_lengths_test\u001b[39m.\u001b[39mappend(tmp)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/franc/Documents/GitHub/AIMOVE_AGV_AI/mediapipe_dtw.ipynb#ch0000022?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(train_arrays_lengths)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_arrays_lengths' is not defined"
     ]
    }
   ],
   "source": [
    "train_arrays_lengths_test=[]\n",
    "\n",
    "for i in range(train_arrays.shape[0]):\n",
    "    tmp=[]\n",
    "    ok=0\n",
    "    for j in range(int(train_arrays[i].shape[0]/30)):\n",
    "        tmp.append(30)\n",
    "    tmp.append(train_arrays[i].shape[0] - (j+1)*30)\n",
    "    print(tmp)\n",
    "    train_arrays_lengths_test.append(tmp)\n",
    "\n",
    "print(train_arrays_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read video for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\\\Users\\\\franc\\\\Desktop\\\\RT_Detection_AGV\\\\data\\\\test\\\\five\\test1.mp4\n",
      "Ignoring empty camera frame.\n",
      "C:\\\\Users\\\\franc\\\\Desktop\\\\RT_Detection_AGV\\\\data\\\\test\\\\pouce\\pouce_test.mp4\n",
      "Ignoring empty camera frame.\n",
      "(2, 35, 42)\n"
     ]
    }
   ],
   "source": [
    "path = r'C:\\Users\\franc\\Desktop\\RT_Detection_AGV\\data\\test'\n",
    "test_dir=[]\n",
    "\n",
    "classes = next(os.walk( path) )\n",
    "classes=classes[1]\n",
    "\n",
    "for num_classes in range(len(classes)):\n",
    "    test_dir.append(glob.glob(path+\"\\\\\"+classes[num_classes]))\n",
    "test_dir\n",
    "\n",
    "for gesture in range(len(test_dir)):\n",
    "    for filename in glob.iglob(str(test_dir[gesture])[2:-2]+'\\\\\\\\*', recursive=True):\n",
    "        print(filename)\n",
    "        V=read_video(filename).to_numpy()\n",
    "        continue\n",
    "    if 'test' in str(test_dir[gesture]): \n",
    "        V=V[:35, 1:]\n",
    "    V = np.expand_dims(V, axis = 0)\n",
    "    if(gesture==0): test_arrays=V\n",
    "    else: test_arrays = np.append(test_arrays, V, axis=0)\n",
    "\n",
    "print(test_arrays.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  3.40it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from hmmlearn.hmm import GaussianHMM \n",
    "import numpy as np\n",
    "import glob\n",
    "import tqdm\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "states = 6\n",
    "cov_type = 'spherical'\n",
    "n_iter = 10000\n",
    "tol=0.000001\n",
    "algorithm ='viterbi' \n",
    "hmm_models=[]\n",
    "\n",
    "for hmm_model_num in tqdm.tqdm(range(len(train_arrays))):\n",
    "    model1=GaussianHMM(n_components=int(states), covariance_type=str(cov_type),n_iter = n_iter, tol =tol,algorithm=algorithm,\n",
    "                       verbose=False, params=\"stmc\").fit(train_arrays[hmm_model_num],train_arrays_lengths[hmm_model_num]) #7\n",
    "    hmm_models.append(model1)\n",
    "\n",
    "# for hmm_model_num in tqdm.tqdm(range(len(train_arrays))):\n",
    "#     model1=GaussianHMM(n_components=int(states), covariance_type=str(cov_type),algorithm=algorithm,\n",
    "#                        verbose=False, params=\"stmc\").fit(train_arrays[hmm_model_num][1:],train_arrays_lengths[hmm_model_num]) #7\n",
    "#     hmm_models.append(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in range(len(test_dir)):\n",
    "    test_arrays[sample]\n",
    "    print(test_arrays[sample].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8265.09105247698, -12579.550363024162]\n",
      "Sample :  \\five || Best model :  five\n",
      "[-10571.669182690724, -6713.907237563317]\n",
      "Sample :  pouce || Best model :  pouce\n"
     ]
    }
   ],
   "source": [
    "for sample in range(len(test_dir)):\n",
    "    resultats=[]\n",
    "    for hmm_model_num in range(len(hmm_models)):\n",
    "        res=hmm_models[hmm_model_num].score(test_arrays[sample][:30])\n",
    "        resultats.append(res)\n",
    "    print(resultats)\n",
    "    ide=resultats.index(max(resultats))\n",
    "    print(\"Sample : \", str(test_dir[sample])[-7:-2], \"|| Best model : \", classes[ide])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T[0].shape[0]+T[1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 42)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T=test_arrays\n",
    "\n",
    "T.reshape(70,42).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le dossier est vide\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "def read_pickle(file_name = \"save_train_data.pkl\"): #To read pinkle file\n",
    "    # open_file = open(file_name, \"rb\")\n",
    "    # train_arrays = pickle.load(open_file)\n",
    "    train_arrays=np.load(file_name)\n",
    "    # open_file.close()\n",
    "    return train_arrays\n",
    "\n",
    "read_pickle().shape[0]\n",
    "\n",
    "if(read_pickle().shape[0] == 0):\n",
    "    print(\"Le dossier est vide\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 35, 42)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_arrays.shape\n",
    "test_arrays2=np.array\n",
    "for i in range(test_arrays.shape[0]):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 42)\n",
      "(10, 42)\n"
     ]
    }
   ],
   "source": [
    "test_arrays[0][:30,:].shape\n",
    "\n",
    "test_arrays[1][:30,:].shape\n",
    "\n",
    "new_train_arrays=test_arrays[0][:30,:]\n",
    "new_train_arrays=np.append(new_train_arrays,test_arrays[1][:30,:],axis=0)\n",
    "print(new_train_arrays.shape)\n",
    "\n",
    "new_test_arrays=test_arrays[0][30:,:]\n",
    "new_test_arrays=np.append(new_test_arrays,test_arrays[1][30:,:],axis=0)\n",
    "print(new_test_arrays.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import mixture\n",
    "gmm = mixture.GaussianMixture(n_components=2, max_iter=1000, covariance_type='full').fit(new_train_arrays)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "labels = gmm.predict(new_test_arrays)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "probs = gmm.predict_proba(new_test_arrays)\n",
    "print(probs[:].round(3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'c' argument has 10 elements, which is inconsistent with 'x' and 'y' with size 60.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\axes\\_axes.py:4221\u001b[0m, in \u001b[0;36mAxes._parse_scatter_color_args\u001b[1;34m(c, edgecolors, kwargs, xsize, get_next_color_func)\u001b[0m\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/axes/_axes.py?line=4219'>4220</a>\u001b[0m \u001b[39mtry\u001b[39;00m:  \u001b[39m# Is 'c' acceptable as PathCollection facecolors?\u001b[39;00m\n\u001b[1;32m-> <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/axes/_axes.py?line=4220'>4221</a>\u001b[0m     colors \u001b[39m=\u001b[39m mcolors\u001b[39m.\u001b[39;49mto_rgba_array(c)\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/axes/_axes.py?line=4221'>4222</a>\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\colors.py:377\u001b[0m, in \u001b[0;36mto_rgba_array\u001b[1;34m(c, alpha)\u001b[0m\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/colors.py?line=375'>376</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/colors.py?line=376'>377</a>\u001b[0m     rgba \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([to_rgba(cc) \u001b[39mfor\u001b[39;00m cc \u001b[39min\u001b[39;00m c])\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/colors.py?line=378'>379</a>\u001b[0m \u001b[39mif\u001b[39;00m alpha \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\colors.py:377\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/colors.py?line=375'>376</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/colors.py?line=376'>377</a>\u001b[0m     rgba \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([to_rgba(cc) \u001b[39mfor\u001b[39;00m cc \u001b[39min\u001b[39;00m c])\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/colors.py?line=378'>379</a>\u001b[0m \u001b[39mif\u001b[39;00m alpha \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\colors.py:187\u001b[0m, in \u001b[0;36mto_rgba\u001b[1;34m(c, alpha)\u001b[0m\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/colors.py?line=185'>186</a>\u001b[0m \u001b[39mif\u001b[39;00m rgba \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# Suppress exception chaining of cache lookup failure.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/colors.py?line=186'>187</a>\u001b[0m     rgba \u001b[39m=\u001b[39m _to_rgba_no_colorcycle(c, alpha)\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/colors.py?line=187'>188</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\colors.py:269\u001b[0m, in \u001b[0;36m_to_rgba_no_colorcycle\u001b[1;34m(c, alpha)\u001b[0m\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/colors.py?line=267'>268</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39miterable(c):\n\u001b[1;32m--> <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/colors.py?line=268'>269</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid RGBA argument: \u001b[39m\u001b[39m{\u001b[39;00morig_c\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/colors.py?line=269'>270</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(c) \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m]:\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid RGBA argument: 0.0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\franc\\Documents\\GitHub\\AIMOVE_AGV_AI\\mediapipe_dtw.ipynb Cell 34'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/franc/Documents/GitHub/AIMOVE_AGV_AI/mediapipe_dtw.ipynb#ch0000030?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/franc/Documents/GitHub/AIMOVE_AGV_AI/mediapipe_dtw.ipynb#ch0000030?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39;49mscatter(new_train_arrays[:, \u001b[39m0\u001b[39;49m], new_train_arrays[:, \u001b[39m1\u001b[39;49m], c\u001b[39m=\u001b[39;49mlabels, cmap\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mviridis\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\pyplot.py:2807\u001b[0m, in \u001b[0;36mscatter\u001b[1;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/pyplot.py?line=2801'>2802</a>\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mscatter)\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/pyplot.py?line=2802'>2803</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mscatter\u001b[39m(\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/pyplot.py?line=2803'>2804</a>\u001b[0m         x, y, s\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, c\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, marker\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, cmap\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, norm\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/pyplot.py?line=2804'>2805</a>\u001b[0m         vmin\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, vmax\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, alpha\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, linewidths\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m,\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/pyplot.py?line=2805'>2806</a>\u001b[0m         edgecolors\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, plotnonfinite\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m-> <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/pyplot.py?line=2806'>2807</a>\u001b[0m     __ret \u001b[39m=\u001b[39m gca()\u001b[39m.\u001b[39mscatter(\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/pyplot.py?line=2807'>2808</a>\u001b[0m         x, y, s\u001b[39m=\u001b[39ms, c\u001b[39m=\u001b[39mc, marker\u001b[39m=\u001b[39mmarker, cmap\u001b[39m=\u001b[39mcmap, norm\u001b[39m=\u001b[39mnorm,\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/pyplot.py?line=2808'>2809</a>\u001b[0m         vmin\u001b[39m=\u001b[39mvmin, vmax\u001b[39m=\u001b[39mvmax, alpha\u001b[39m=\u001b[39malpha, linewidths\u001b[39m=\u001b[39mlinewidths,\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/pyplot.py?line=2809'>2810</a>\u001b[0m         edgecolors\u001b[39m=\u001b[39medgecolors, plotnonfinite\u001b[39m=\u001b[39mplotnonfinite,\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/pyplot.py?line=2810'>2811</a>\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m({\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m: data} \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {}), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/pyplot.py?line=2811'>2812</a>\u001b[0m     sci(__ret)\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/pyplot.py?line=2812'>2813</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m __ret\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\__init__.py:1412\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/__init__.py?line=1408'>1409</a>\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/__init__.py?line=1409'>1410</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(ax, \u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/__init__.py?line=1410'>1411</a>\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/__init__.py?line=1411'>1412</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m func(ax, \u001b[39m*\u001b[39m\u001b[39mmap\u001b[39m(sanitize_sequence, args), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/__init__.py?line=1413'>1414</a>\u001b[0m     bound \u001b[39m=\u001b[39m new_sig\u001b[39m.\u001b[39mbind(ax, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/__init__.py?line=1414'>1415</a>\u001b[0m     auto_label \u001b[39m=\u001b[39m (bound\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mget(label_namer)\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/__init__.py?line=1415'>1416</a>\u001b[0m                   \u001b[39mor\u001b[39;00m bound\u001b[39m.\u001b[39mkwargs\u001b[39m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\axes\\_axes.py:4387\u001b[0m, in \u001b[0;36mAxes.scatter\u001b[1;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/axes/_axes.py?line=4383'>4384</a>\u001b[0m \u001b[39mif\u001b[39;00m edgecolors \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/axes/_axes.py?line=4384'>4385</a>\u001b[0m     orig_edgecolor \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39medgecolor\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/axes/_axes.py?line=4385'>4386</a>\u001b[0m c, colors, edgecolors \u001b[39m=\u001b[39m \\\n\u001b[1;32m-> <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/axes/_axes.py?line=4386'>4387</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parse_scatter_color_args(\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/axes/_axes.py?line=4387'>4388</a>\u001b[0m         c, edgecolors, kwargs, x\u001b[39m.\u001b[39;49msize,\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/axes/_axes.py?line=4388'>4389</a>\u001b[0m         get_next_color_func\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_patches_for_fill\u001b[39m.\u001b[39;49mget_next_color)\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/axes/_axes.py?line=4390'>4391</a>\u001b[0m \u001b[39mif\u001b[39;00m plotnonfinite \u001b[39mand\u001b[39;00m colors \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/axes/_axes.py?line=4391'>4392</a>\u001b[0m     c \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mma\u001b[39m.\u001b[39mmasked_invalid(c)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\axes\\_axes.py:4227\u001b[0m, in \u001b[0;36mAxes._parse_scatter_color_args\u001b[1;34m(c, edgecolors, kwargs, xsize, get_next_color_func)\u001b[0m\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/axes/_axes.py?line=4224'>4225</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/axes/_axes.py?line=4225'>4226</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m valid_shape:\n\u001b[1;32m-> <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/axes/_axes.py?line=4226'>4227</a>\u001b[0m         \u001b[39mraise\u001b[39;00m invalid_shape_exception(c\u001b[39m.\u001b[39msize, xsize) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/axes/_axes.py?line=4227'>4228</a>\u001b[0m     \u001b[39m# Both the mapping *and* the RGBA conversion failed: pretty\u001b[39;00m\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/axes/_axes.py?line=4228'>4229</a>\u001b[0m     \u001b[39m# severe failure => one may appreciate a verbose feedback.\u001b[39;00m\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/axes/_axes.py?line=4229'>4230</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/axes/_axes.py?line=4230'>4231</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mc\u001b[39m\u001b[39m'\u001b[39m\u001b[39m argument must be a color, a sequence of colors, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/axes/_axes.py?line=4231'>4232</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mor a sequence of numbers, not \u001b[39m\u001b[39m{\u001b[39;00mc\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: 'c' argument has 10 elements, which is inconsistent with 'x' and 'y' with size 60."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(new_train_arrays[:, 0], new_train_arrays[:, 1], c=labels, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 2 into shape (1940,42)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\franc\\Documents\\GitHub\\AIMOVE_AGV_AI\\mediapipe_dtw.ipynb Cell 32'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/franc/Documents/GitHub/AIMOVE_AGV_AI/mediapipe_dtw.ipynb#ch0000072?line=0'>1</a>\u001b[0m T\u001b[39m=\u001b[39mtrain_arrays\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/franc/Documents/GitHub/AIMOVE_AGV_AI/mediapipe_dtw.ipynb#ch0000072?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(T\u001b[39m.\u001b[39mshape)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/franc/Documents/GitHub/AIMOVE_AGV_AI/mediapipe_dtw.ipynb#ch0000072?line=2'>3</a>\u001b[0m T\u001b[39m.\u001b[39;49mreshape(train_arrays[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m]\u001b[39m+\u001b[39;49mtrain_arrays[\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m],\u001b[39m42\u001b[39;49m)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 2 into shape (1940,42)"
     ]
    }
   ],
   "source": [
    "T=train_arrays\n",
    "print(T.shape)\n",
    "T.reshape(train_arrays[0].shape[0]+train_arrays[1].shape[0],42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. Estimator expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\franc\\Documents\\GitHub\\AIMOVE_AGV_AI\\mediapipe_dtw.ipynb Cell 32'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/franc/Documents/GitHub/AIMOVE_AGV_AI/mediapipe_dtw.ipynb#ch0000030?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m \u001b[39mimport\u001b[39;00m mixture\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/franc/Documents/GitHub/AIMOVE_AGV_AI/mediapipe_dtw.ipynb#ch0000030?line=1'>2</a>\u001b[0m gmm \u001b[39m=\u001b[39m mixture\u001b[39m.\u001b[39;49mGaussianMixture(n_components\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\u001b[39m.\u001b[39;49mfit(test_arrays)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\mixture\\_base.py:198\u001b[0m, in \u001b[0;36mBaseMixture.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/mixture/_base.py?line=171'>172</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/mixture/_base.py?line=172'>173</a>\u001b[0m     \u001b[39m\"\"\"Estimate model parameters with the EM algorithm.\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/mixture/_base.py?line=173'>174</a>\u001b[0m \n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/mixture/_base.py?line=174'>175</a>\u001b[0m \u001b[39m    The method fits the model ``n_init`` times and sets the parameters with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/mixture/_base.py?line=195'>196</a>\u001b[0m \u001b[39m        The fitted mixture.\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/mixture/_base.py?line=196'>197</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/mixture/_base.py?line=197'>198</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_predict(X, y)\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/mixture/_base.py?line=198'>199</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\mixture\\_base.py:228\u001b[0m, in \u001b[0;36mBaseMixture.fit_predict\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/mixture/_base.py?line=200'>201</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit_predict\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/mixture/_base.py?line=201'>202</a>\u001b[0m     \u001b[39m\"\"\"Estimate model parameters using X and predict the labels for X.\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/mixture/_base.py?line=202'>203</a>\u001b[0m \n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/mixture/_base.py?line=203'>204</a>\u001b[0m \u001b[39m    The method fits the model n_init times and sets the parameters with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/mixture/_base.py?line=225'>226</a>\u001b[0m \u001b[39m        Component labels.\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/mixture/_base.py?line=226'>227</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/mixture/_base.py?line=227'>228</a>\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, dtype\u001b[39m=\u001b[39;49m[np\u001b[39m.\u001b[39;49mfloat64, np\u001b[39m.\u001b[39;49mfloat32], ensure_min_samples\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/mixture/_base.py?line=228'>229</a>\u001b[0m     \u001b[39mif\u001b[39;00m X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_components:\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/mixture/_base.py?line=229'>230</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/mixture/_base.py?line=230'>231</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected n_samples >= n_components \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/mixture/_base.py?line=231'>232</a>\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got n_components = \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_components\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/mixture/_base.py?line=232'>233</a>\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mn_samples = \u001b[39m\u001b[39m{\u001b[39;00mX\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/mixture/_base.py?line=233'>234</a>\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:566\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/base.py?line=563'>564</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/base.py?line=564'>565</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/base.py?line=565'>566</a>\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/base.py?line=566'>567</a>\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/base.py?line=567'>568</a>\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:794\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/utils/validation.py?line=788'>789</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/utils/validation.py?line=789'>790</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUnable to convert array of bytes/strings \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/utils/validation.py?line=790'>791</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39minto decimal numbers with dtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/utils/validation.py?line=791'>792</a>\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/utils/validation.py?line=792'>793</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nd \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m--> <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/utils/validation.py?line=793'>794</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/utils/validation.py?line=794'>795</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/utils/validation.py?line=795'>796</a>\u001b[0m         \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/utils/validation.py?line=796'>797</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/utils/validation.py?line=798'>799</a>\u001b[0m \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/utils/validation.py?line=799'>800</a>\u001b[0m     _assert_all_finite(array, allow_nan\u001b[39m=\u001b[39mforce_all_finite \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mallow-nan\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 3. Estimator expected <= 2."
     ]
    }
   ],
   "source": [
    "from sklearn import mixture\n",
    "gmm = mixture.GaussianMixture(n_components=2).fit(test_arrays)\n",
    "\n",
    "#plt.scatter(X[:, 0], X[:, 1], c=classes, s=40, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = gmm.predict_proba(test_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "(995, 43)\n",
      "(44, 43)\n",
      "(945, 43)\n",
      "(39, 43)\n"
     ]
    }
   ],
   "source": [
    "#from data import Data\n",
    "\n",
    "train_df_five=read_video(r'C:\\Users\\franc\\Desktop\\RT_Detection_AGV\\data\\five\\test3.mp4')\n",
    "test_df_five=read_video(r'C:\\Users\\franc\\Desktop\\RT_Detection_AGV\\data\\five\\test1.mp4')\n",
    "\n",
    "train_df_pouce=read_video(r'C:\\Users\\franc\\Desktop\\RT_Detection_AGV\\data\\pouce\\pouce_train.mp4')\n",
    "test_df_pouce=read_video(r'C:\\Users\\franc\\Desktop\\RT_Detection_AGV\\data\\pouce\\pouce_test.mp4')\n",
    "\n",
    "print(train_df_five.shape)\n",
    "print(test_df_five.shape)\n",
    "print(train_df_pouce.shape)\n",
    "print(test_df_pouce.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 43)\n",
      "9\n",
      "[100, 100, 100, 100, 100, 100, 100, 100, 100]\n"
     ]
    }
   ],
   "source": [
    "train_arrays=train_df_five.to_numpy()\n",
    "train_arrays=train_arrays[:900, :]\n",
    "#lenght of each sample\n",
    "train_arrays_lengths=[100,100,100,100,100,100,100,100,100]\n",
    "print(train_arrays.shape)\n",
    "print(len(train_arrays_lengths))\n",
    "print(train_arrays_lengths)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 43)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_arrays = np.expand_dims(train_arrays, axis = 0)\n",
    "train_arrays[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 43)\n",
      "9\n",
      "[100, 100, 100, 100, 100, 100, 100, 100, 100]\n"
     ]
    }
   ],
   "source": [
    "train_arrays22=train_df_pouce.to_numpy()\n",
    "\n",
    "train_arrays22=train_arrays22[:900, :]\n",
    "#lenght of each sample\n",
    "train_arrays_lengths22=[100,100,100,100,100,100,100,100,100]\n",
    "print(train_arrays22.shape)\n",
    "print(len(train_arrays_lengths22))\n",
    "print(train_arrays_lengths22)\n",
    "\n",
    "train_arrays22 = np.expand_dims(train_arrays22, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_arrays = np.append(train_arrays, train_arrays22, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1940, 42)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_arrays_lengths=[train_arrays_lengths,train_arrays_lengths22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44, 42)\n"
     ]
    }
   ],
   "source": [
    "#df=df[['x_r_hand','y_r_hand']]    \n",
    "data=df.to_numpy()\n",
    "\n",
    "#data=data[30:34,1:]\n",
    "data=data[:,1:]\n",
    "print(data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some data\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "X, y_true = make_blobs(n_samples=400, centers=4,\n",
    "                       cluster_std=0.60, random_state=0)\n",
    "X = X[:, ::-1] # flip axes for better plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_arrays.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 42)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T=np.array(train_arrays[1][:100,:])\n",
    "T=np.append(T,train_arrays[0][:100,:] ,axis=0)\n",
    "T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x123364d2800>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import mixture\n",
    "gmm = mixture.GaussianMixture(n_components=2).fit(T)\n",
    "\n",
    "plt.scatter(T[:400, 0], T[:400, 1], s=40, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 42)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_arrays[0][:5,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "probs = gmm.predict_proba(test_arrays[0][:5,:])\n",
    "print(probs[:5].round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "probs = gmm.predict_proba(test_arrays[1][:5,:])\n",
    "print(probs[:5].round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
